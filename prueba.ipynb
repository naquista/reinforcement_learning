{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttqOLol_oIJG",
    "outputId": "e7b26d16-a6d3-45af-ca5f-332a2330427a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 530      |\n",
      "|    ep_rew_mean     | -318     |\n",
      "| time/              |          |\n",
      "|    fps             | 1985     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | -206        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1368        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017058915 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 96.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 175         |\n",
      "|    ep_rew_mean          | -64.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1196        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014883096 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.0668      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 70          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 106         |\n",
      "|    ep_rew_mean          | -16.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1163        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013126868 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.7        |\n",
      "|    ep_rew_mean          | 24.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1146        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011174452 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.7        |\n",
      "|    ep_rew_mean          | 30.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1133        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012505954 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.8       |\n",
      "|    ep_rew_mean          | 34.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1118       |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01101483 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.176      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 291        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26          |\n",
      "|    ep_rew_mean          | 35.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1109        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012706703 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 261         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.6        |\n",
      "|    ep_rew_mean          | 36.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1101        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018425642 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.964      |\n",
      "|    explained_variance   | 0.0432      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 21.8         |\n",
      "|    ep_rew_mean          | 36.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1099         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065516634 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.928       |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 107          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.7         |\n",
      "|    ep_rew_mean          | 38.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1099         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105195185 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.871       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 73.6         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.6         |\n",
      "|    ep_rew_mean          | 37.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1098         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029015196 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.822       |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 54.6         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 20.2         |\n",
      "|    ep_rew_mean          | 38.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1097         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046273116 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.782       |\n",
      "|    explained_variance   | 0.192        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 40           |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.5        |\n",
      "|    ep_rew_mean          | 37.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007544228 |\n",
      "|    clip_fraction        | 0.029       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | 38.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009666475 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.4        |\n",
      "|    ep_rew_mean          | 39.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007949904 |\n",
      "|    clip_fraction        | 0.0371      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 46.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 39.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1096        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006077022 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.7         |\n",
      "|    ep_rew_mean          | 40           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1095         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046957815 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.691        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 7.37         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    value_loss           | 21.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.6         |\n",
      "|    ep_rew_mean          | 40.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1094         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027330667 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 4.8          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.5         |\n",
      "|    ep_rew_mean          | 40.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1094         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030148118 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.48         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 7.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.4        |\n",
      "|    ep_rew_mean          | 41.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1091        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004249474 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.13        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 3.74        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.3         |\n",
      "|    ep_rew_mean          | 41.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1091         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036007022 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.611        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00847     |\n",
      "|    value_loss           | 1.61         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.2        |\n",
      "|    ep_rew_mean          | 41.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006453915 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.356      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.389       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.761       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.1         |\n",
      "|    ep_rew_mean          | 42.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1091         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034016203 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0734       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    value_loss           | 0.554        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.1        |\n",
      "|    ep_rew_mean          | 42          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001450097 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1090         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024550245 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.288       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.209        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 0.372        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.1         |\n",
      "|    ep_rew_mean          | 42.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1089         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030204607 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.266       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.1          |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 42.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003596717 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.1         |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1087         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025714806 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.267       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0117       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 0.0158       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.1         |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1085         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053006317 |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.259       |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.022       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1084         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034157177 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0872       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1084         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059486595 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.237       |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00441     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    value_loss           | 0.115        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1084         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024052337 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.246       |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 0.0557       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 42.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1084        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003617521 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.233      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0059      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 0.0489      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.1         |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1083         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063439566 |\n",
      "|    clip_fraction        | 0.0728       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0107      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 0.0801       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1083         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026138201 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0141       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    value_loss           | 0.0567       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 42.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001973079 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1082         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021213244 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.213       |\n",
      "|    explained_variance   | 1            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0165      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 0.00752      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1082         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032153209 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0121       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 0.0768       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1082         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023102085 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.213       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.013       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 0.0466       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18          |\n",
      "|    ep_rew_mean          | 42.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008324558 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 0.0757      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1080         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044977446 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.222       |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00951     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.00175      |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 18            |\n",
      "|    ep_rew_mean          | 42.3          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1080          |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 81            |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030145896 |\n",
      "|    clip_fraction        | 0.00845       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.218        |\n",
      "|    explained_variance   | 0.993         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.113         |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    value_loss           | 0.15          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 18            |\n",
      "|    ep_rew_mean          | 42.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1081          |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 83            |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039717573 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.221        |\n",
      "|    explained_variance   | 0.99          |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.00108       |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.00155      |\n",
      "|    value_loss           | 0.219         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 18            |\n",
      "|    ep_rew_mean          | 42.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1081          |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 85            |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071627693 |\n",
      "|    clip_fraction        | 0.0105        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.214        |\n",
      "|    explained_variance   | 0.991         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.00228       |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.000183     |\n",
      "|    value_loss           | 0.192         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 18            |\n",
      "|    ep_rew_mean          | 42.6          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1081          |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025783488 |\n",
      "|    clip_fraction        | 0.0142        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.205        |\n",
      "|    explained_variance   | 0.991         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.13          |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | 0.000362      |\n",
      "|    value_loss           | 0.194         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1081         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044654305 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.222        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 0.0391       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 42.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1081         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012517143 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.197       |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    value_loss           | 0.255        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 18            |\n",
      "|    ep_rew_mean          | 42.4          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1082          |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 92            |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079188973 |\n",
      "|    clip_fraction        | 0.00752       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.197        |\n",
      "|    explained_variance   | 0.984         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | 0.107         |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.00522      |\n",
      "|    value_loss           | 0.357         |\n",
      "-------------------------------------------\n",
      "Entrenamiento completado y visualización finalizada.\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "import torch as th\n",
    "\n",
    "# Definición del entorno GoToTopLeft en una grilla de 10x10 con obstáculos alternados\n",
    "class GoToTopLeftEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"console\", \"human\"]}\n",
    "    LEFT = 0\n",
    "    RIGHT = 1\n",
    "    UP = 2\n",
    "    DOWN = 3\n",
    "\n",
    "    def __init__(self, grid_size=10, obstacle_row=5):\n",
    "        super(GoToTopLeftEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.obstacle_row = obstacle_row\n",
    "        self.agent_pos = [grid_size - 1, grid_size - 1]  # Inicializa al agente en la esquina inferior derecha\n",
    "        n_actions = 4\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0, high=self.grid_size - 1, shape=(2,), dtype=np.int32\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None) -> Tuple[np.array, dict]:\n",
    "        self.agent_pos = [self.grid_size - 1, self.grid_size - 1]  # Reposiciona al agente en la esquina inicial\n",
    "        return np.array(self.agent_pos), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == self.LEFT:\n",
    "            self.agent_pos[1] = max(self.agent_pos[1] - 1, 0)\n",
    "        elif action == self.RIGHT:\n",
    "            self.agent_pos[1] = min(self.agent_pos[1] + 1, self.grid_size - 1)\n",
    "        elif action == self.UP:\n",
    "            self.agent_pos[0] = max(self.agent_pos[0] - 1, 0)\n",
    "        elif action == self.DOWN:\n",
    "            self.agent_pos[0] = min(self.agent_pos[0] + 1, self.grid_size - 1)\n",
    "\n",
    "        # Verificar si el agente está en una celda de obstáculo\n",
    "        if self.agent_pos[0] == self.obstacle_row and self.agent_pos[1] % 2 == 0:\n",
    "            reward = -5  # Penalización alta por caer en el obstáculo\n",
    "            terminated = False  # El episodio no termina en entrenamiento\n",
    "        else:\n",
    "            # Condición de éxito: el agente llega a la posición superior izquierda (0,0)\n",
    "            terminated = self.agent_pos == [0, 0]\n",
    "            distance_to_goal = np.linalg.norm(np.array([0, 0]) - np.array(self.agent_pos))  # Distancia a la meta\n",
    "            reward = -0.1 - distance_to_goal * 0.05  # Penalización progresiva por distancia\n",
    "            if terminated:\n",
    "                reward += 50  # Recompensa alta en la meta\n",
    "\n",
    "        return np.array(self.agent_pos), reward, terminated, False, {}\n",
    "\n",
    "# Entrenamiento del agente con el modelo PPO\n",
    "env = GoToTopLeftEnv(grid_size=10, obstacle_row=5)\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    device=\"cuda\",\n",
    "    n_steps=2048,  # Incremento para mejorar el horizonte de aprendizaje\n",
    "    learning_rate=1e-4,  # Aprendizaje más lento para mayor estabilidad\n",
    "    gamma=0.99,  # Mayor importancia a la recompensa futura\n",
    "    ent_coef=0.01,  # Coeficiente de entropía para fomentar exploración\n",
    ")\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "# Función para calcular la entropía de la política para cada celda\n",
    "def compute_entropy_grid(grid_size, model):\n",
    "    entropy_grid = np.zeros((grid_size, grid_size))\n",
    "    for row in range(grid_size):\n",
    "        for col in range(grid_size):\n",
    "            state_tensor = th.tensor([[row, col]], dtype=th.float32, device=model.device)\n",
    "            with th.no_grad():\n",
    "                latent = model.policy.extract_features(state_tensor)\n",
    "                latent_pi = model.policy.mlp_extractor.forward_actor(latent)\n",
    "                action_logits = model.policy.action_net(latent_pi)\n",
    "                action_probs = th.softmax(action_logits, dim=-1)\n",
    "                entropy = -th.sum(action_probs * th.log(action_probs + 1e-8)).item()\n",
    "                entropy_grid[row, col] = entropy\n",
    "    return entropy_grid\n",
    "\n",
    "\n",
    "\n",
    "# Configuración de Pygame para visualizar después del entrenamiento\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((500, 500))\n",
    "pygame.display.set_caption(\"Go To Top Left - Agente Entrenado con Obstáculos\")\n",
    "WHITE = (255, 255, 255)\n",
    "BLUE = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "GRAY = (200, 200, 200)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)  # Color para las casillas de obstáculos\n",
    "BLOCK_SIZE = 50  # Tamaño de cada bloque en la grilla\n",
    "FONT = pygame.font.SysFont(None, 18)  # Fuente para mostrar los valores Q\n",
    "\n",
    "# Función para dibujar el entorno en Pygame con valores Q y flechas\n",
    "def draw_env_with_q_and_policy(state, grid_size=10, obstacle_row=5, model=None):\n",
    "    screen.fill(WHITE)\n",
    "    for row in range(grid_size):\n",
    "        for col in range(grid_size):\n",
    "            # Marca las celdas de la fila de obstáculos en rojo en posiciones pares\n",
    "            if row == obstacle_row and col % 2 == 0:\n",
    "                color = RED\n",
    "            elif (row, col) == (0, 0):\n",
    "                color = GREEN  # Meta\n",
    "            elif (row, col) == (state[0], state[1]):\n",
    "                color = BLUE  # Agente\n",
    "            else:\n",
    "                color = GRAY  # Celdas normales\n",
    "            \n",
    "            pygame.draw.rect(screen, color, (col * BLOCK_SIZE, row * BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE))\n",
    "\n",
    "            # Predecir el valor Q para cada celda y dibujar en el centro\n",
    "            if model:\n",
    "                state_tensor = th.tensor([[row, col]], dtype=th.float32, device=model.device)\n",
    "                q_value = model.policy.predict_values(state_tensor).item()\n",
    "                #text = FONT.render(f\"{q_value:.1f}\", True, BLACK)\n",
    "                #text_rect = text.get_rect(center=(col * BLOCK_SIZE + BLOCK_SIZE // 2, row * BLOCK_SIZE + BLOCK_SIZE // 2))\n",
    "                #screen.blit(text, text_rect)\n",
    "\n",
    "                # Obtener la acción óptima para la celda actual y dibujar una flecha\n",
    "                action, _ = model.predict(np.array([row, col]), deterministic=True)\n",
    "                arrow_start = (col * BLOCK_SIZE + BLOCK_SIZE // 2, row * BLOCK_SIZE + BLOCK_SIZE // 2)\n",
    "                arrow_end = arrow_start\n",
    "                if action == env.UP:\n",
    "                    arrow_end = (arrow_start[0], arrow_start[1] - BLOCK_SIZE // 3)\n",
    "                elif action == env.DOWN:\n",
    "                    arrow_end = (arrow_start[0], arrow_start[1] + BLOCK_SIZE // 3)\n",
    "                elif action == env.LEFT:\n",
    "                    arrow_end = (arrow_start[0] - BLOCK_SIZE // 3, arrow_start[1])\n",
    "                elif action == env.RIGHT:\n",
    "                    arrow_end = (arrow_start[0] + BLOCK_SIZE // 3, arrow_start[1])\n",
    "                pygame.draw.line(screen, BLACK, arrow_start, arrow_end, 2)\n",
    "                pygame.draw.circle(screen, BLACK, arrow_end, 3)\n",
    "\n",
    "    # Dibujar las líneas de la cuadrícula\n",
    "    for x in range(0, grid_size * BLOCK_SIZE, BLOCK_SIZE):\n",
    "        pygame.draw.line(screen, BLACK, (x, 0), (x, grid_size * BLOCK_SIZE))\n",
    "    for y in range(0, grid_size * BLOCK_SIZE, BLOCK_SIZE):\n",
    "        pygame.draw.line(screen, BLACK, (0, y), (grid_size * BLOCK_SIZE, y))\n",
    "\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Visualización en Pygame del agente entrenado\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    draw_env_with_q_and_policy(obs, grid_size=10, obstacle_row=5, model=model)\n",
    "    pygame.time.delay(500)\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            done = True\n",
    "            pygame.quit()\n",
    "            break\n",
    "\n",
    "    if done and reward > 0:\n",
    "        pygame.time.delay(300)\n",
    "        break\n",
    "\n",
    "pygame.quit()\n",
    "# Calcular entropías\n",
    "entropy_grid = compute_entropy_grid(10, model)\n",
    "\n",
    "print(\"Entrenamiento completado y visualización finalizada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Q aproximados en formato de cuadrícula:\n",
      " 50.07  49.88  49.20  48.56  48.01  47.25  46.46  45.60  44.65  43.75\n",
      " 49.89  49.26  48.56  47.96  47.21  46.46  45.63  44.70  43.81  42.99\n",
      " 49.33  48.57  47.90  47.15  46.43  45.64  44.75  43.88  43.04  42.21\n",
      " 48.57  47.84  47.10  46.41  45.64  44.79  43.95  43.10  42.21  41.33\n",
      " 47.76  47.06  46.40  45.65  44.84  44.02  43.16  42.22  41.22  40.32\n",
      " 47.01  46.40  45.71  44.91  44.07  43.18  42.20  41.13  40.10  39.26\n",
      " 46.38  45.78  45.03  44.17  43.23  42.18  41.04  39.91  38.92  38.18\n",
      " 45.81  45.17  44.36  43.39  42.29  41.07  39.83  38.69  37.78  37.13\n",
      " 45.26  44.57  43.67  42.58  41.34  39.99  38.69  37.57  36.71  36.11\n",
      " 44.71  43.97  42.97  41.79  40.44  39.02  37.68  36.54  35.67  35.06\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "def print_q_grid(grid_size, model):\n",
    "    print(\"Valores Q aproximados en formato de cuadrícula:\")\n",
    "    q_grid = np.zeros((grid_size, grid_size))  # Crear una cuadrícula vacía para almacenar los valores Q\n",
    "    for row in range(grid_size):\n",
    "        for col in range(grid_size):\n",
    "            # Crear el estado actual como tensor de PyTorch\n",
    "            state_tensor = th.tensor([[row, col]], dtype=th.float32, device=model.device)\n",
    "            # Predecir el valor Q para la celda actual\n",
    "            q_value = model.policy.predict_values(state_tensor).item()\n",
    "            q_grid[row, col] = q_value  # Almacenar en la cuadrícula\n",
    "\n",
    "    # Imprimir la cuadrícula\n",
    "    for row in range(grid_size):\n",
    "        print(\" \".join(f\"{q_grid[row, col]:6.2f}\" for col in range(grid_size)))\n",
    "\n",
    "# Imprimimos los valores Q en formato de cuadrícula\n",
    "print_q_grid(10, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.65115982e-01 7.37776048e-04 1.94382708e-04 1.38853196e-04\n",
      "  1.24654485e-04 1.20574005e-04 1.20958881e-04 1.23695121e-04\n",
      "  1.27627354e-04 1.32417903e-04]\n",
      " [7.46581098e-03 2.87042499e-01 2.33846926e-03 4.15045506e-04\n",
      "  2.17751192e-04 1.60415992e-04 1.35765484e-04 1.23349208e-04\n",
      "  1.17260846e-04 1.14714116e-04]\n",
      " [3.87447973e-04 6.01004204e-03 6.96181297e-01 3.45876850e-02\n",
      "  3.46694910e-03 9.85951046e-04 4.63417789e-04 2.84570706e-04\n",
      "  2.05189761e-04 1.64142330e-04]\n",
      " [2.32983934e-04 2.93563615e-04 3.50245414e-03 1.43437371e-01\n",
      "  6.68594360e-01 1.48605153e-01 2.67059766e-02 6.50414405e-03\n",
      "  2.14624265e-03 9.23017098e-04]\n",
      " [2.10253347e-04 1.66249738e-04 2.96557759e-04 1.54268043e-03\n",
      "  1.21157272e-02 7.72892535e-02 3.41012269e-01 6.96494102e-01\n",
      "  3.86907965e-01 1.03584677e-01]\n",
      " [2.05502802e-04 1.49329906e-04 1.60205236e-04 2.90694123e-04\n",
      "  7.58984010e-04 2.04650150e-03 5.22827869e-03 1.36170955e-02\n",
      "  3.90061997e-02 1.24575317e-01]\n",
      " [2.04577882e-04 1.47866755e-04 1.35598413e-04 1.69648309e-04\n",
      "  2.74470076e-04 4.64574754e-04 7.38363713e-04 1.13417231e-03\n",
      "  1.79139618e-03 3.07734124e-03]\n",
      " [2.04205193e-04 1.49824918e-04 1.29937107e-04 1.38761912e-04\n",
      "  1.81777665e-04 2.54541403e-04 3.38112819e-04 4.23714751e-04\n",
      "  5.20084344e-04 6.46475703e-04]\n",
      " [2.03683303e-04 1.52751410e-04 1.29798485e-04 1.27932377e-04\n",
      "  1.49078827e-04 1.90308652e-04 2.35921718e-04 2.75273080e-04\n",
      "  3.09610972e-04 3.44225409e-04]\n",
      " [2.03230287e-04 1.55945803e-04 1.31423876e-04 1.24004480e-04\n",
      "  1.34152593e-04 1.61155855e-04 1.93686705e-04 2.20591843e-04\n",
      "  2.40423571e-04 2.56605505e-04]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(entropy_grid)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_entropy_grid(entropy_grid):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(entropy_grid, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar(label='Entropía')\n",
    "    plt.title('Mapa de Entropía en la Cuadrícula')\n",
    "    plt.xlabel('Columna')\n",
    "    plt.ylabel('Fila')\n",
    "    plt.gca().invert_yaxis()  # Invertir el eje y para que la fila 0 esté arriba\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso (si entropy_grid es una matriz de ejemplo)\n",
    "plot_entropy_grid(entropy_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SD-FSSuKoIJF",
    "uUUkScRxoIJQ"
   ],
   "include_colab_link": true,
   "name": "stable_baselines.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "aprendizajeporrefuerzos-7kOLcKCl-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
